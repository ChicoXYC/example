{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data projects\n",
    "\n",
    "This notebook is used for introcuding some of my representative works(non-confidential) related to data scraping, data analyzing, data visualization."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Web Scraping\n",
    "\n",
    "There are basically 3 kinds of web-scraping methods for extrating data from websites. The following will give you basic information about each method and how to apply those methods to different cases.\n",
    "\n",
    "1. Static web scraping\n",
    "2. Browser emulation\n",
    "3. Social media scraping"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1. Static web craping\n",
    "Most traditonal websites can be scraped by this method. They don't use technology like dynamic loading, and the limitation about scraping this kind of website is usually small.\n",
    "\n",
    "Example: HK GOLDEN, jobsdb, [carpark hk](http://www.carparkhk.com/transaction-records.php?page=1), [initium mews](https://github.com/hupili/python-for-data-and-media-communication-gitbook/blob/master/notes-week-07.md#bonus-scrape-all-articles-features-of-all-pages)\n",
    "\n",
    "How to scrape: Requests、Beautifulsoup / Re"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2. Browser emulation\n",
    "Websites with dynamic loading can be scraped by this method. They usually have speed limitation and Anti craping barriers, which need some human actions to activate certain content loading.\n",
    "\n",
    "Example: [Openrice](https://mp.weixin.qq.com/s/aFfa7WlyT0vwXBlDYvacCg),[CNN](https://github.com/hupili/python-for-data-and-media-communication-gitbook/blob/master/notes-week-08.md#advanced-version-all-pages), [JD](https://nbviewer.jupyter.org/github/iiiJenny/python-data-assignments/blob/master/assignment1/JD_scraper_final.ipynb)\n",
    "\n",
    "How to scrape: Selenium broser emulation, User agent, Handling Anti-scraping"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3. Social media scraping\n",
    "Social media website usually can be scraped by the method 1 and 2, but need some further steps like Website login model to support. The limitation about scraping social media is higher than above two.\n",
    "\n",
    "Example: [Weibo keywords searching - \"核电站\"](https://github.com/ChicoXYC/exercise/blob/master/weibo_scraper/%E6%A0%B8%E7%94%B5%E7%AB%990311-0312.csv), [Twitter keywords searhcing - \"山竹台风\"](https://nbviewer.jupyter.org/github/ChicoXYC/exercise/blob/master/twitter-selenium/twitter-try2.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Data analysis and visualization\n",
    "\n",
    "The following are analysis reports or notebooks about how to perform analysis related to different kind of data. You can click to view the full stories."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Text data: \n",
    "[A text analysis for comments of video channels - TF-IDF,Topic modeling,NLP](https://nbviewer.jupyter.org/github/ChicoXYC/exercise/blob/master/text-mining-test/text-mining-final.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Geographical data: [Flying in the sky, a report of air crash worldwide](https://dnnsociety.org/2018/04/30/flying-in-the-sky-a-report-of-air-crash-worldwide/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Network data: [Les Misérables class demo](https://github.com/hupili/python-for-data-and-media-communication-gitbook/blob/master/notes-week-14.md#common-network-analysis-routine-via-les-mis%C3%A9rables-dataset)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Numerical data: [Correlations between abscent rate with grade performance](https://github.com/hupili/python-for-data-and-media-communication-gitbook/blob/master/notes-week-10.md#correlation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* [Elder Suicide in HK, honorable mention in data journalism competition, HKBU](https://chicoxyc.github.io/Elder-Suicide-in-Hong-Kong/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
